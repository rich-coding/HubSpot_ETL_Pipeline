{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be718757",
   "metadata": {},
   "source": [
    "| Questions                                              | Answers                                                                                                                                                                                                                                                                                           |\n",
    "|--------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| What is your usual IDE?                                | I have worked with Spyder and I am retaking it, because my master degree in Artificial Intelligence.                                                                                                                                                                                                                                                          |\n",
    "| What are the advantages of this IDE over the others?   | In my bachelor degree (Physics) I used Spyder because that was the IDE that we need to use for scientific modeling and graphing. I know that Spyder has integrate many scientific tools as iPython, Numpy and Scipy, and I used them to process and analize experimental data and apply statistics and mathematics concepts.|\n",
    "| Which of the items resulted in the most computational time for you? Add time in seconds. | The upload process consumed the most computational time because I couldn't push all 100 contacts at once due to the JSON format for properties. Consequently, I had to send them one by one. The total time for this process was 1560 seconds, equivalent to 26 minutes. The next large time was of 174s = 2min + 53s to Transformation Data process. It is important mentioned that the size of data increased in this second time.                               |\n",
    "| If you have any public portfolio (e.g., AI, computer vision, data processing…), please share the link with us. | I have a machine learning project that I completed last year. Although I haven't uploaded it to GitHub yet, I am in the process of completing the documentation. For now, you can access it through Google Colab: [ML Project](https://colab.research.google.com/drive/1nj4hZlfjcNUK8-uPQUFpZWoAo-QnhQ5I?usp=sharing). On the other hand, this is my GitHub, but it is under construction: [https://github.com/rich-coding](https://github.com/rich-coding) |\n",
    "| **(Optional Question)** Propose an idea of how you could store data such as “Street Adrees” with the associated “Technical Test - Create Date” in HubSpot for the duplicates in order to avoid losing this data from the duplicated records.| First, I will create a single line property in HupSpot for Contacts objects in Contacts Information group. Then, I could include the new property as a new column in dataframe and duplicatesManagement function, in such way that it merges addresses and “Technical Test - Create Date” as a tuple. Finally, the duplicatesManagement function separated each tuple by ';' to the new property but in the same cell; it will help to its future extraction. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984e4a87",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
